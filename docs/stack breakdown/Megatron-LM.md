[paper](https://arxiv.org/abs/1909.08053)
Still very actively maintained by [NVIDIA](https://developer.nvidia.com/megatron-core). 
> including tensor, sequence, pipeline, context, and MoE expert parallelism

> training resiliency features such as automatic restart, fault/hang detection, and [fast distributed checkpointing](https://developer.nvidia.com/blog/train-generative-ai-models-more-efficiently-with-new-nvidia-megatron-core-functionalities/).

**What you get:**

- Composable transformer building blocks (attention, MLP, etc.)
- Advanced parallelism strategies (TP, PP, DP, EP, CP)
- Pipeline schedules and distributed optimizers
- Mixed precision support (FP16, BF16, FP8)
- GPU-optimized kernels and memory management
- High-performance dataloaders and dataset utilities
- Model architectures (LLaMA, Qwen, GPT, Mixtral, Mamba, etc.)